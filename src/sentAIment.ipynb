{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Recurrent Neural Networks (RNN) and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('all')    # run just once\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Flatten, Input, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  A very, very, very slow-moving, aimless movie ...  0\n",
       "1  Not sure who was more lost - the flat characte...  0\n",
       "2  Attempting artiness with black & white and cle...  0\n",
       "3       Very little music or anything to speak of.    0\n",
       "4  The best scene in the movie was when Gerardo i...  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from txt\n",
    "imdb = pd.read_csv('../data/imdb_labelled.txt', sep='\\t', header=None)\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = pd.read_csv('../data/amazon_cells_labelled.txt', sep='\\t', header=None)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0                           Wow... Loved this place.  1\n",
       "1                                 Crust is not good.  0\n",
       "2          Not tasty and the texture was just nasty.  0\n",
       "3  Stopped by during the late May bank holiday of...  1\n",
       "4  The selection on the menu was great and so wer...  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = pd.read_csv('../data/yelp_labelled.txt', sep='\\t', header=None)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1748 entries, 0 to 1747\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1748 non-null   object\n",
      " 1   1       1748 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 27.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# merge the datasets\n",
    "data = pd.merge(imdb, amazon, how='outer')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2748 entries, 0 to 2747\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       2748 non-null   object\n",
      " 1   1       2748 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.merge(data, yelp, how='outer')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1], dtype='int64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change column names \n",
    "data.columns = ['sentence', 'sentiment']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    1386\n",
       "0    1362\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where '0' is the positive reviews and '1' is the negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence     0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates() \n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# grafico de barras para la columna quality\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"sentiment\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cree una función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    # Tokenice el texto utilizando la función word_tokenize()\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Pase el texto a minúscula\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Elimine las stopwords utilizando stopwords.words('english')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lematice los tokens utilizando WordNetLemmatizer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Una los tokens de los procesos previos en una sola cadena\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    # Retorne el texto procesado\n",
    "    return processed_text\n",
    "\n",
    "# Aplique su función a la columna reviewText del dataframe\n",
    "data['sentence'] = data['sentence'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>, , slow-moving , aimless movie distressed , d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sure lost - flat character audience , nearly h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempting artiness black &amp; white clever camer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little music anything speak .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best scene movie gerardo trying find song keep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0  , , slow-moving , aimless movie distressed , d...          0\n",
       "1  sure lost - flat character audience , nearly h...          0\n",
       "2  attempting artiness black & white clever camer...          0\n",
       "3                      little music anything speak .          0\n",
       "4  best scene movie gerardo trying find song keep...          1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['sentence']\n",
    "y = data['sentiment']\n",
    "\n",
    "# Divida el dataframe en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a DummyClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_train = dummy.predict(X_train)\n",
    "y_pred_test = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN METRICS\n",
      "\n",
      "Accuracy: 0.5023547880690737\n",
      "Precision: 0.25117739403453687\n",
      "Recall: 0.5\n",
      "f1-score: 0.3343782654127482\n",
      "[[  0 951]\n",
      " [  0 960]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       951\n",
      "           1       0.50      1.00      0.67       960\n",
      "\n",
      "    accuracy                           0.50      1911\n",
      "   macro avg       0.25      0.50      0.33      1911\n",
      "weighted avg       0.25      0.50      0.34      1911\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# print accuracy, precision, recall and f1-score\n",
    "print(\"TRAIN METRICS\\n\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Precision:\", precision_score(y_train, y_pred_train, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_train, y_pred_train, average='macro'))\n",
    "print(\"f1-score:\", f1_score(y_train, y_pred_train, average='macro'))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(classification_report(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST METRICS\n",
      "\n",
      "Accuracy: 0.5073170731707317\n",
      "Precision: 0.25365853658536586\n",
      "Recall: 0.5\n",
      "f1-score: 0.3365695792880259\n",
      "[[  0 404]\n",
      " [  0 416]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       404\n",
      "           1       0.51      1.00      0.67       416\n",
      "\n",
      "    accuracy                           0.51       820\n",
      "   macro avg       0.25      0.50      0.34       820\n",
      "weighted avg       0.26      0.51      0.34       820\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST METRICS\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_test, average='macro'))\n",
    "print(\"f1-score:\", f1_score(y_test, y_pred_test, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cree un objeto Tokenizer\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "# updates internal vocabulary based on a list of texts\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# transforms text to a sequence of integers\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "# pad sequences to the same length\n",
    "sequences_matrix_train = pad_sequences(sequences_train, maxlen=max_len)\n",
    "sequences_matrix_test = pad_sequences(sequences_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1896                                         give 2 thumb\n",
       "1096                       new battery work great phone .\n",
       "2624                     've better bagel grocery store .\n",
       "492              's bad 's actually worth seeing reason .\n",
       "1012                    good product - incredible value .\n",
       "                              ...                        \n",
       "1651           love able use one headset land-line cell .\n",
       "1104                 work like charm .. work advertised .\n",
       "1139                                 poor sound quality .\n",
       "1306    seller understanding patient , would definitel...\n",
       "864     keyboard nice compromise full qwerty basic cel...\n",
       "Name: sentence, Length: 1911, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[86, 62, 574],\n",
       " [87, 44, 17, 6, 7],\n",
       " [34, 33, 472],\n",
       " [2, 19, 2, 150, 105, 473, 575],\n",
       " [3, 35, 232, 350],\n",
       " [474, 210, 18],\n",
       " [2, 8, 4, 37, 717, 211, 233, 113, 475, 2, 718],\n",
       " [21, 576, 719, 398, 720, 261, 351],\n",
       " [],\n",
       " [139, 63, 399, 44, 44],\n",
       " [476, 234, 151, 25, 23, 113],\n",
       " [477, 121, 400, 577, 6, 18],\n",
       " [140],\n",
       " [235, 478],\n",
       " [3, 236, 10, 721, 578, 352, 172, 722, 723, 724, 262, 191],\n",
       " [121, 192, 95, 309, 27, 725, 479, 152, 114, 25],\n",
       " [64, 263, 153, 29, 237, 264],\n",
       " [27, 719, 2, 65],\n",
       " [122, 7, 154],\n",
       " [106, 23, 57, 13, 40, 123],\n",
       " [96, 16, 141],\n",
       " [480, 310, 66, 726, 481, 311, 49],\n",
       " [3, 35, 3, 727],\n",
       " [3, 26],\n",
       " [579],\n",
       " [37, 124, 20, 353, 1, 17],\n",
       " [1, 97, 728, 63, 401, 54],\n",
       " [10],\n",
       " [580, 238, 581, 5],\n",
       " [10, 1, 19, 55, 312, 351, 2, 58, 478, 81],\n",
       " [121, 6, 173, 482, 155],\n",
       " [402, 153, 21, 265, 20],\n",
       " [6, 50],\n",
       " [313, 3, 314, 3, 729],\n",
       " [10, 142, 398, 55, 151, 403, 47],\n",
       " [16, 96, 45, 730, 20, 156],\n",
       " [731, 315, 404, 732],\n",
       " [140, 4, 6, 405, 174, 2, 733, 582, 125, 734, 193, 27],\n",
       " [98, 1, 4],\n",
       " [49],\n",
       " [354, 483, 73],\n",
       " [21, 31, 583, 316],\n",
       " [46, 355],\n",
       " [19, 4],\n",
       " [99],\n",
       " [88, 266, 59, 8, 239],\n",
       " [22, 356, 2, 212, 23, 357, 75],\n",
       " [358, 67, 484, 70, 155],\n",
       " [75, 317, 115, 7],\n",
       " [7, 359, 20, 58, 34, 24],\n",
       " [11, 3, 5],\n",
       " [32, 68, 240, 584],\n",
       " [241, 13],\n",
       " [59, 235, 65, 585, 100, 735, 106, 107, 69],\n",
       " [101, 736, 213],\n",
       " [406, 42, 194, 48, 53, 11, 73, 213, 354],\n",
       " [318, 6, 73],\n",
       " [4, 214, 101, 157, 57, 67],\n",
       " [215, 36, 101, 13, 34, 70, 29, 1, 737],\n",
       " [126, 26, 18],\n",
       " [407, 175, 586, 408, 17, 7],\n",
       " [485, 360],\n",
       " [2, 195, 48, 738, 739, 740, 2, 17],\n",
       " [241, 6, 355, 6],\n",
       " [30, 158, 196, 216, 7, 82],\n",
       " [13, 176, 127, 197, 587, 741],\n",
       " [8, 22, 4, 128, 319],\n",
       " [194, 4, 47, 42],\n",
       " [88, 66, 16, 588, 589, 2, 159, 198, 198, 65],\n",
       " [7, 409, 742, 195],\n",
       " [60, 486, 80, 743, 744, 267, 745, 155],\n",
       " [410, 217, 487, 36, 16, 218, 54],\n",
       " [361, 590],\n",
       " [108, 177, 143, 591, 592],\n",
       " [210, 28],\n",
       " [219, 746, 747, 748],\n",
       " [242, 488, 75, 116, 56, 109, 320, 20, 20],\n",
       " [7, 30, 268, 269],\n",
       " [110, 362, 144],\n",
       " [178, 100, 411, 7, 321],\n",
       " [21, 179, 12, 412, 122, 32, 314],\n",
       " [18, 593, 489],\n",
       " [21, 22, 594],\n",
       " [177, 47, 88, 12, 749, 595, 596, 243, 27],\n",
       " [32, 750],\n",
       " [322, 31, 115],\n",
       " [197, 160, 145, 89, 83],\n",
       " [71, 124, 51, 113, 363, 180, 353, 597, 47, 751, 179, 3],\n",
       " [23],\n",
       " [354],\n",
       " [4, 3, 84],\n",
       " [75, 598, 24, 752, 490, 64, 90, 41, 193, 364, 491, 2, 323],\n",
       " [12],\n",
       " [270, 753, 270, 754, 271, 8, 8],\n",
       " [111, 747],\n",
       " [7],\n",
       " [117, 97, 49],\n",
       " [29, 30, 319, 55, 413],\n",
       " [324],\n",
       " [8, 33, 325],\n",
       " [492, 52, 755, 414],\n",
       " [102, 415, 599, 17, 6, 600, 756, 7, 757, 53, 54, 244],\n",
       " [4, 272, 109, 758],\n",
       " [365, 7, 161],\n",
       " [98, 1],\n",
       " [107, 326, 67, 150, 113, 49, 7, 759, 309, 7, 82],\n",
       " [1, 129, 13],\n",
       " [98, 1],\n",
       " [29, 91, 273],\n",
       " [15, 192, 493, 127, 96, 105, 601],\n",
       " [43, 602, 2, 21, 52, 494, 123],\n",
       " [30, 33, 216, 760, 7, 34],\n",
       " [416, 35, 17, 20],\n",
       " [274, 417],\n",
       " [36, 162, 327],\n",
       " [17, 3],\n",
       " [603, 761, 13, 13, 10, 142],\n",
       " [495, 322, 141, 56],\n",
       " [604, 16, 22, 47, 762],\n",
       " [605, 127, 109, 366, 318],\n",
       " [245],\n",
       " [117, 275],\n",
       " [3],\n",
       " [28, 76, 43],\n",
       " [328, 29, 763, 33, 329, 84, 163, 328, 199, 246, 764, 330, 130, 763],\n",
       " [53, 418, 81, 163, 26],\n",
       " [2, 56, 765, 164, 181, 367, 324, 313],\n",
       " [419, 131, 2, 33, 276, 76],\n",
       " [277, 496, 366],\n",
       " [153, 21, 497, 182, 42, 766, 368],\n",
       " [767, 278, 261, 179, 12, 369, 493],\n",
       " [45],\n",
       " [275],\n",
       " [75, 598],\n",
       " [50, 61, 11, 16, 42, 200],\n",
       " [498, 20, 768, 331, 499, 13],\n",
       " [769, 16, 17, 279, 770],\n",
       " [771],\n",
       " [72, 495, 74],\n",
       " [321, 370, 13, 34, 318, 325, 52, 3],\n",
       " [70, 7, 165, 125, 234, 40, 220],\n",
       " [420, 107, 601, 280, 157, 606, 201],\n",
       " [130, 82, 607, 72],\n",
       " [102, 192, 17, 264],\n",
       " [15, 3, 35],\n",
       " [95, 101, 75],\n",
       " [608, 281, 34, 609, 165, 314, 7, 421, 610, 216, 53, 26, 772],\n",
       " [44, 107, 132],\n",
       " [23, 3, 371, 332, 23, 199, 47],\n",
       " [133, 500],\n",
       " [213, 611, 15, 398, 55, 501, 202],\n",
       " [40, 15, 77, 118, 1, 17],\n",
       " [58, 10, 18, 34],\n",
       " [7, 180],\n",
       " [71, 29, 97, 422, 333, 502, 612, 372, 282, 215, 773, 774, 125, 774, 4, 48],\n",
       " [352, 139, 3, 47],\n",
       " [11],\n",
       " [38, 775, 41, 111, 85, 575, 182, 115],\n",
       " [1, 61, 26, 776],\n",
       " [40, 166, 324, 503, 373, 504, 777, 613, 2, 334],\n",
       " [146, 44, 7, 237, 23, 335],\n",
       " [61, 6],\n",
       " [88, 12, 336],\n",
       " [],\n",
       " [92, 77, 406, 221, 778],\n",
       " [11, 51, 505, 65],\n",
       " [580, 67, 5, 283, 370, 134],\n",
       " [133, 614, 4, 74, 9, 74],\n",
       " [211, 195],\n",
       " [13, 5],\n",
       " [59, 5],\n",
       " [172, 615, 167, 13, 506],\n",
       " [27, 362],\n",
       " [374],\n",
       " [779, 29, 336, 337, 30, 23, 112],\n",
       " [375, 2, 15, 6, 81],\n",
       " [507, 58, 24, 53, 780],\n",
       " [18, 134, 3],\n",
       " [247, 29, 163, 781, 114, 357, 12],\n",
       " [71, 143, 508, 21, 32, 65, 782],\n",
       " [509, 95, 423, 783, 5],\n",
       " [784, 616, 785, 23, 11, 55, 424, 222, 510],\n",
       " [17, 12, 425, 17, 8, 70, 7],\n",
       " [726, 147, 117],\n",
       " [607, 117],\n",
       " [10, 15, 3, 70, 272, 338],\n",
       " [617, 103, 16, 86, 617, 103],\n",
       " [353, 203, 281],\n",
       " [183],\n",
       " [34, 147, 284, 15, 12],\n",
       " [1, 17],\n",
       " [117, 242, 7],\n",
       " [7, 30, 122, 66],\n",
       " [273, 91, 5, 476, 786],\n",
       " [140, 11],\n",
       " [2, 21, 55, 5, 31],\n",
       " [39, 35, 50],\n",
       " [2, 105],\n",
       " [83, 426],\n",
       " [285, 286, 509, 65, 152],\n",
       " [44, 84, 21, 6],\n",
       " [21, 7, 374, 68, 63, 787, 374, 376],\n",
       " [184, 25, 318],\n",
       " [162, 35],\n",
       " [135, 281, 64, 427, 428, 17, 38],\n",
       " [10, 262, 66, 85, 334, 43],\n",
       " [618, 3, 164],\n",
       " [44, 481, 180, 619],\n",
       " [33, 76],\n",
       " [4,\n",
       "  39,\n",
       "  788,\n",
       "  195,\n",
       "  620,\n",
       "  621,\n",
       "  89,\n",
       "  136,\n",
       "  620,\n",
       "  788,\n",
       "  620,\n",
       "  37,\n",
       "  287,\n",
       "  288,\n",
       "  168,\n",
       "  45,\n",
       "  4,\n",
       "  239,\n",
       "  193,\n",
       "  358,\n",
       "  363,\n",
       "  789,\n",
       "  620,\n",
       "  788],\n",
       " [185, 191, 494, 60, 223, 248],\n",
       " [213, 377],\n",
       " [52, 75, 317],\n",
       " [71, 19],\n",
       " [289, 5, 622, 6, 5],\n",
       " [360, 790],\n",
       " [19, 5, 19, 356, 3, 93, 791, 81, 175, 1, 249, 178],\n",
       " [98, 1, 792],\n",
       " [429, 339],\n",
       " [223, 28, 66, 732],\n",
       " [39],\n",
       " [224, 25, 23],\n",
       " [3, 511],\n",
       " [290, 601],\n",
       " [110, 17, 793, 80, 512, 288],\n",
       " [218, 340],\n",
       " [96, 290, 311, 7],\n",
       " [8, 22, 204, 10, 123],\n",
       " [129, 112],\n",
       " [60, 23, 430],\n",
       " [794, 378, 513, 410, 155],\n",
       " [250, 17],\n",
       " [101, 13, 1, 59, 93, 145],\n",
       " [514, 264],\n",
       " [5, 20, 768, 8, 22, 515, 34, 186],\n",
       " [77],\n",
       " [201, 730, 795, 267, 287, 92, 796],\n",
       " [280, 27, 101, 44, 84],\n",
       " [11, 65],\n",
       " [18, 6, 28, 623, 60, 155],\n",
       " [379, 482, 233, 797, 54],\n",
       " [71, 169, 371, 50, 288],\n",
       " [51, 13, 359, 107],\n",
       " [250, 2, 119, 380, 514, 380, 7, 376],\n",
       " [94, 193, 624],\n",
       " [96, 23],\n",
       " [113, 73, 262, 10, 120, 18],\n",
       " [111, 377, 381, 12],\n",
       " [126, 776, 22, 291, 43],\n",
       " [268, 262],\n",
       " [516, 66, 157, 57, 431, 798, 35, 128],\n",
       " [625, 4, 292, 8, 4, 32, 20, 430, 2, 799, 626],\n",
       " [251, 50, 429, 30, 426],\n",
       " [42, 33, 170, 627, 68],\n",
       " [5, 94, 128, 517, 427, 78],\n",
       " [327, 242, 68],\n",
       " [100, 420, 10, 158, 142, 13],\n",
       " [283, 362, 382, 1, 278],\n",
       " [383, 12],\n",
       " [7, 28, 82],\n",
       " [800, 150, 399, 44, 60],\n",
       " [],\n",
       " [59, 265, 85, 329, 314, 628],\n",
       " [629],\n",
       " [801, 802, 31, 66],\n",
       " [432, 205, 252, 40, 25, 23],\n",
       " [187, 2, 803, 293, 630, 804, 631, 353, 98, 1],\n",
       " [29, 141, 116],\n",
       " [433, 15, 30, 632, 412, 2, 83],\n",
       " [148, 224, 792, 7, 432, 805],\n",
       " [414, 4, 30, 434],\n",
       " [250, 435, 329, 91, 806],\n",
       " [294, 6],\n",
       " [5, 807, 417, 2, 200, 793, 33],\n",
       " [4, 237, 43, 633],\n",
       " [195, 164],\n",
       " [64, 518, 381, 192],\n",
       " [634, 214, 216, 122],\n",
       " [194],\n",
       " [295, 225, 515, 334, 5, 12],\n",
       " [57, 13, 141, 59, 808],\n",
       " [436, 374, 115, 7, 79, 116],\n",
       " [809, 437, 358, 67, 8, 146, 177],\n",
       " [105, 629],\n",
       " [28, 146, 810, 438, 742, 183],\n",
       " [96, 811, 368, 20, 105, 439],\n",
       " [15, 157, 372],\n",
       " [351],\n",
       " [51, 4, 34, 440, 74, 69],\n",
       " [8, 46, 38, 725, 812, 154, 635, 1, 296, 636],\n",
       " [218, 340, 472],\n",
       " [206, 813, 80, 10, 1, 814],\n",
       " [58, 493, 24],\n",
       " [815, 253],\n",
       " [7, 69, 332, 6],\n",
       " [314, 254, 374],\n",
       " [39, 36],\n",
       " [816, 519, 6, 637, 492, 120, 241],\n",
       " [817, 818],\n",
       " [270, 242, 62, 67, 115, 297, 510, 255, 297, 204],\n",
       " [70, 137, 118, 28, 284, 118, 207, 244, 283],\n",
       " [1, 25],\n",
       " [21, 12, 191, 243, 384, 281, 341],\n",
       " [10, 226, 520, 226, 29],\n",
       " [108, 488, 31, 819, 819, 819, 53, 66, 413, 638],\n",
       " [18, 210, 400],\n",
       " [521, 13, 820, 48, 12, 435, 198],\n",
       " [522, 639, 272, 640, 517],\n",
       " [250, 641, 78, 78, 813, 89, 47, 821],\n",
       " [135, 42, 256, 822],\n",
       " [21, 55, 99, 823, 315, 68],\n",
       " [6, 118],\n",
       " [6, 35],\n",
       " [156, 3, 261, 262],\n",
       " [10, 6, 108, 642],\n",
       " [523],\n",
       " [254, 97, 643, 505],\n",
       " [61, 10, 202, 644],\n",
       " [55, 131, 824, 5],\n",
       " [100, 124, 12, 425],\n",
       " [81, 12, 5, 227, 4, 43, 12, 4],\n",
       " [524, 645, 81],\n",
       " [342, 721, 169],\n",
       " [15, 287, 164],\n",
       " [437, 76, 13, 121, 30, 25, 192],\n",
       " [6, 591],\n",
       " [254],\n",
       " [28, 94, 29, 1, 737, 87, 8],\n",
       " [129],\n",
       " [11, 123, 485, 34, 825, 148, 826, 580, 69, 421],\n",
       " [66, 10, 65],\n",
       " [44, 83],\n",
       " [576, 827],\n",
       " [164,\n",
       "  525,\n",
       "  828,\n",
       "  526,\n",
       "  476,\n",
       "  646,\n",
       "  57,\n",
       "  829,\n",
       "  174,\n",
       "  8,\n",
       "  41,\n",
       "  527,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  166,\n",
       "  43],\n",
       " [105],\n",
       " [3, 5, 6, 298],\n",
       " [39, 18],\n",
       " [441, 67, 293, 128, 385, 93, 55, 31, 197, 108, 820, 234, 234, 32, 361],\n",
       " [54, 577, 624],\n",
       " [253, 337],\n",
       " [124, 20, 830, 36, 600, 225, 586, 147],\n",
       " [93, 86, 109, 188, 280, 625, 831, 832, 136, 183, 103],\n",
       " [442, 210],\n",
       " [140, 15],\n",
       " [256, 24, 299, 43],\n",
       " [10, 144],\n",
       " [19, 73],\n",
       " [4, 220, 292, 329, 218, 101, 13, 4],\n",
       " [268, 210, 146, 633, 249],\n",
       " [53, 26, 125, 39, 49, 36, 115, 309, 403, 309, 49, 36, 115, 62],\n",
       " [206, 131, 64, 33],\n",
       " [11, 528, 8, 103, 647, 10],\n",
       " [37, 648, 16, 440, 443, 151, 176, 519],\n",
       " [18, 649, 10, 3, 252],\n",
       " [63, 154, 57, 152, 161],\n",
       " [650, 444, 253, 92, 228],\n",
       " [3, 384, 524, 236, 3, 10, 236],\n",
       " [59],\n",
       " [5],\n",
       " [30, 317, 529],\n",
       " [412, 65],\n",
       " [833, 152],\n",
       " [530, 291, 531, 11, 444, 1, 386, 445, 834],\n",
       " [5, 446, 404],\n",
       " [2, 8, 4, 221, 59, 106, 387, 37, 386, 257],\n",
       " [3, 44, 70, 15, 338],\n",
       " [16, 45],\n",
       " [107, 205, 370, 13, 483, 162, 25, 23],\n",
       " [28, 207, 619, 651, 358, 267],\n",
       " [130, 532, 582],\n",
       " [292],\n",
       " [607, 61, 23, 101, 13],\n",
       " [42, 652, 12, 297, 653],\n",
       " [167, 65, 22, 652, 24],\n",
       " [135, 835, 820, 323, 514],\n",
       " [88, 96, 25, 23],\n",
       " [5, 3, 654, 655],\n",
       " [7, 113, 170, 71, 446, 2, 836, 7],\n",
       " [44, 39, 837],\n",
       " [388, 271],\n",
       " [838, 656, 839, 240, 6, 5, 43, 2, 76],\n",
       " [234, 19, 5, 24, 32],\n",
       " [447],\n",
       " [208, 840, 827, 193],\n",
       " [21, 60, 23, 448, 80, 39, 18],\n",
       " [114, 477, 7, 2, 15, 48, 200, 258, 280, 187],\n",
       " [449, 99, 169],\n",
       " [250, 836, 150, 72, 115, 200, 389, 390, 7, 841],\n",
       " [],\n",
       " [793, 300, 842, 405, 582, 657, 41, 84],\n",
       " [795, 213, 831],\n",
       " [40, 77, 5, 16, 130, 280, 100, 17, 5],\n",
       " [27, 243, 596],\n",
       " [10, 232, 94, 658, 92, 12, 516],\n",
       " [618, 120],\n",
       " [39, 35, 796, 327],\n",
       " [18],\n",
       " [843],\n",
       " [11, 52, 3, 46, 89, 127],\n",
       " [11, 528, 103],\n",
       " [11, 589],\n",
       " [39, 188],\n",
       " [1, 107, 101],\n",
       " [26, 35],\n",
       " [131, 7, 110, 46, 130, 183, 364, 265, 281, 20],\n",
       " [2, 405, 844, 149, 13, 445, 271],\n",
       " [185, 757, 61, 124, 51, 91],\n",
       " [368, 794, 845, 192],\n",
       " [30, 36, 134, 15],\n",
       " [826, 3, 215, 533, 178, 31, 48],\n",
       " [1, 61, 77],\n",
       " [355, 1, 42, 33],\n",
       " [247, 164, 63, 158, 94, 624],\n",
       " [534, 6, 450],\n",
       " [530, 102, 143, 177, 98, 1, 77],\n",
       " [6, 10, 161, 18],\n",
       " [91, 535],\n",
       " [2, 210],\n",
       " [176, 15, 3, 10],\n",
       " [410],\n",
       " [109, 229, 343],\n",
       " [185, 21, 232],\n",
       " [216, 126],\n",
       " [216, 36, 39],\n",
       " [221, 206, 451, 30, 7, 602, 13, 51, 212, 7, 44, 84, 331],\n",
       " [1, 72, 485, 4, 4, 534, 193, 136, 174, 2, 516],\n",
       " [579],\n",
       " [69, 622, 122, 402, 174],\n",
       " [22, 492, 594, 100],\n",
       " [229, 5, 15, 46],\n",
       " [391, 87, 279, 846, 7, 118],\n",
       " [1, 72, 11, 784, 847, 10, 24, 603],\n",
       " [759, 177],\n",
       " [44, 84, 56, 101, 55, 279],\n",
       " [58, 24],\n",
       " [344, 220, 848, 392],\n",
       " [70, 1, 48, 849],\n",
       " [135, 363, 22, 189],\n",
       " [536, 344, 659],\n",
       " [419, 167, 167, 646, 167, 22, 58, 11, 131, 22, 167, 2, 24, 603],\n",
       " [8, 58, 128, 13],\n",
       " [850, 375, 290],\n",
       " [336],\n",
       " [51, 13, 24, 60, 65, 73, 56, 332, 81, 161, 851],\n",
       " [46, 401, 179, 12, 248, 789, 10],\n",
       " [233, 3, 17, 533],\n",
       " [133, 139, 16, 25, 23],\n",
       " [25, 472, 122, 87, 407, 7, 294, 6],\n",
       " [852, 77],\n",
       " [34, 7, 537, 286, 66, 2, 22, 489, 7, 34],\n",
       " [10, 26, 196],\n",
       " [211, 22, 147, 36, 53, 26],\n",
       " [62, 574],\n",
       " [162],\n",
       " [418, 53],\n",
       " [12, 257, 402, 54, 200, 392],\n",
       " [853, 854, 3, 26, 137, 118, 2, 42, 252],\n",
       " [3, 350, 17, 169, 783, 586, 137, 519],\n",
       " [538, 834, 11, 16, 275, 392, 1, 49, 660],\n",
       " [19, 539, 286, 18],\n",
       " [50, 3],\n",
       " [58, 7, 24],\n",
       " [236, 10, 22],\n",
       " [57, 90, 401],\n",
       " [4, 161],\n",
       " [22],\n",
       " [367, 291],\n",
       " [1, 251, 5, 6, 150],\n",
       " [4, 57, 47],\n",
       " [41, 5, 20, 330],\n",
       " [102, 846, 178],\n",
       " [223, 37, 25],\n",
       " [219, 21, 452, 661, 362, 364, 7],\n",
       " [187, 230, 597, 110, 4, 77, 28, 517, 64, 126, 111, 138, 197, 540],\n",
       " [5, 32],\n",
       " [142],\n",
       " [85, 111],\n",
       " [172, 159, 662, 663, 12, 855],\n",
       " [1, 117, 35],\n",
       " [78],\n",
       " [453, 2, 231, 502, 1, 433, 220, 856, 857, 356],\n",
       " [339, 9, 75, 451],\n",
       " [28, 48, 144],\n",
       " [2, 271, 338, 768, 664, 405, 205],\n",
       " [6, 11, 141, 89, 736, 255],\n",
       " [107, 67, 4, 21, 19, 20],\n",
       " [3],\n",
       " [2],\n",
       " [290, 171, 58, 43, 274],\n",
       " [274, 359, 29, 858, 54],\n",
       " [51, 134, 3, 341, 537, 859, 7, 850],\n",
       " [136, 17, 169, 137, 113, 602, 830, 133, 56, 614, 180, 301],\n",
       " [207, 162, 132, 6, 665, 639],\n",
       " [391, 36, 3, 13, 162],\n",
       " [233, 254, 33, 33, 860, 8, 34, 861],\n",
       " [98, 1, 66, 1, 12, 541, 1, 97, 8, 454, 5, 105, 13],\n",
       " [25, 160],\n",
       " [10, 39, 18, 3],\n",
       " [40, 310, 95, 35, 533, 170, 148, 1, 301, 411],\n",
       " [1, 814, 259, 21, 430],\n",
       " [182, 48, 455, 182],\n",
       " [102, 862, 863, 862],\n",
       " [22, 7, 864],\n",
       " [70, 10, 325],\n",
       " [542, 64, 543, 228, 523, 59],\n",
       " [191, 158, 202, 456, 168, 258, 191, 202],\n",
       " [865, 39, 90, 496, 64, 48, 5, 725],\n",
       " [611, 666, 3, 532],\n",
       " [22, 147, 864],\n",
       " [667, 126, 26, 426, 866, 867, 20],\n",
       " [27],\n",
       " [144],\n",
       " [170, 781, 527, 176, 3, 1, 97, 141, 626, 254, 668],\n",
       " [868, 37, 30, 647, 67, 23],\n",
       " [166, 345],\n",
       " [669, 11, 285, 69, 670, 139],\n",
       " [17],\n",
       " [415, 599, 42, 326, 439],\n",
       " [457, 217, 13, 785, 346, 29, 49, 544],\n",
       " [542, 7, 19, 44, 84, 645, 869],\n",
       " [302, 5, 360, 17],\n",
       " [21, 212, 3, 188, 671, 545, 343],\n",
       " [156, 383, 199, 458, 3, 47],\n",
       " [228, 26],\n",
       " [6, 380],\n",
       " [817, 303, 672],\n",
       " [5, 616],\n",
       " [6, 10, 18, 339, 429, 86],\n",
       " [203, 449, 20, 224, 389, 225, 68],\n",
       " [448, 304, 205, 835, 212, 370, 51, 40, 423],\n",
       " [70, 27, 532, 582],\n",
       " [17, 169],\n",
       " [191, 65],\n",
       " [377, 19, 160],\n",
       " [233, 302],\n",
       " [3, 837],\n",
       " [238, 227, 4, 150, 104, 227],\n",
       " [537, 155, 18, 52, 338],\n",
       " [257,\n",
       "  2,\n",
       "  170,\n",
       "  136,\n",
       "  870,\n",
       "  871,\n",
       "  872,\n",
       "  330,\n",
       "  246,\n",
       "  9,\n",
       "  870,\n",
       "  871,\n",
       "  9,\n",
       "  870,\n",
       "  871,\n",
       "  329,\n",
       "  84,\n",
       "  577,\n",
       "  39,\n",
       "  873,\n",
       "  5,\n",
       "  25,\n",
       "  20,\n",
       "  490,\n",
       "  114,\n",
       "  4,\n",
       "  9,\n",
       "  874,\n",
       "  6,\n",
       "  298,\n",
       "  9,\n",
       "  373,\n",
       "  148,\n",
       "  5,\n",
       "  579,\n",
       "  129,\n",
       "  13,\n",
       "  160,\n",
       "  14,\n",
       "  874,\n",
       "  52,\n",
       "  42,\n",
       "  875,\n",
       "  4,\n",
       "  9,\n",
       "  2,\n",
       "  546,\n",
       "  5,\n",
       "  14,\n",
       "  263,\n",
       "  90,\n",
       "  673,\n",
       "  876,\n",
       "  14,\n",
       "  111,\n",
       "  211,\n",
       "  12,\n",
       "  654,\n",
       "  87,\n",
       "  78,\n",
       "  14,\n",
       "  749,\n",
       "  874,\n",
       "  417,\n",
       "  14,\n",
       "  268,\n",
       "  14,\n",
       "  4,\n",
       "  421,\n",
       "  294,\n",
       "  14,\n",
       "  674,\n",
       "  1,\n",
       "  316,\n",
       "  675,\n",
       "  14,\n",
       "  402,\n",
       "  144,\n",
       "  328,\n",
       "  491,\n",
       "  14,\n",
       "  75,\n",
       "  4,\n",
       "  171,\n",
       "  459,\n",
       "  14,\n",
       "  32,\n",
       "  272,\n",
       "  877,\n",
       "  5,\n",
       "  14,\n",
       "  51,\n",
       "  251,\n",
       "  4,\n",
       "  140,\n",
       "  9,\n",
       "  168,\n",
       "  229,\n",
       "  758,\n",
       "  71,\n",
       "  9,\n",
       "  135,\n",
       "  667,\n",
       "  251,\n",
       "  263,\n",
       "  38,\n",
       "  878,\n",
       "  220,\n",
       "  771,\n",
       "  268,\n",
       "  266,\n",
       "  747,\n",
       "  816,\n",
       "  263,\n",
       "  104,\n",
       "  260,\n",
       "  758,\n",
       "  14,\n",
       "  433,\n",
       "  351,\n",
       "  16,\n",
       "  37,\n",
       "  676,\n",
       "  263,\n",
       "  38,\n",
       "  92,\n",
       "  748,\n",
       "  14,\n",
       "  41,\n",
       "  21,\n",
       "  501,\n",
       "  14,\n",
       "  163,\n",
       "  144,\n",
       "  14,\n",
       "  129,\n",
       "  13,\n",
       "  14,\n",
       "  196,\n",
       "  14,\n",
       "  58,\n",
       "  276,\n",
       "  29,\n",
       "  25,\n",
       "  14,\n",
       "  15,\n",
       "  32,\n",
       "  641,\n",
       "  14,\n",
       "  126,\n",
       "  93,\n",
       "  14,\n",
       "  175,\n",
       "  1,\n",
       "  28,\n",
       "  332,\n",
       "  803,\n",
       "  748,\n",
       "  138,\n",
       "  298,\n",
       "  495,\n",
       "  427,\n",
       "  14,\n",
       "  448,\n",
       "  298,\n",
       "  2,\n",
       "  59,\n",
       "  5,\n",
       "  1,\n",
       "  14,\n",
       "  16,\n",
       "  28,\n",
       "  3,\n",
       "  32,\n",
       "  387,\n",
       "  547,\n",
       "  14,\n",
       "  3,\n",
       "  32,\n",
       "  5,\n",
       "  6,\n",
       "  5,\n",
       "  359,\n",
       "  8,\n",
       "  879,\n",
       "  5,\n",
       "  24,\n",
       "  32,\n",
       "  9,\n",
       "  5,\n",
       "  6,\n",
       "  93,\n",
       "  740,\n",
       "  298,\n",
       "  880,\n",
       "  881,\n",
       "  206,\n",
       "  16,\n",
       "  773,\n",
       "  880,\n",
       "  881,\n",
       "  351,\n",
       "  78,\n",
       "  511,\n",
       "  41,\n",
       "  8,\n",
       "  359,\n",
       "  882,\n",
       "  677,\n",
       "  9,\n",
       "  5,\n",
       "  446,\n",
       "  14,\n",
       "  4,\n",
       "  673,\n",
       "  717,\n",
       "  333,\n",
       "  287,\n",
       "  739,\n",
       "  14,\n",
       "  450,\n",
       "  434,\n",
       "  91,\n",
       "  4,\n",
       "  14,\n",
       "  300,\n",
       "  312,\n",
       "  302,\n",
       "  9,\n",
       "  250,\n",
       "  19,\n",
       "  4,\n",
       "  883,\n",
       "  19,\n",
       "  14,\n",
       "  19,\n",
       "  182,\n",
       "  19,\n",
       "  641,\n",
       "  196,\n",
       "  64,\n",
       "  31,\n",
       "  8,\n",
       "  883,\n",
       "  19,\n",
       "  14,\n",
       "  276,\n",
       "  226,\n",
       "  14,\n",
       "  342,\n",
       "  839,\n",
       "  226,\n",
       "  14,\n",
       "  884,\n",
       "  226,\n",
       "  14,\n",
       "  64,\n",
       "  226,\n",
       "  14,\n",
       "  226,\n",
       "  14,\n",
       "  46,\n",
       "  9,\n",
       "  149,\n",
       "  9,\n",
       "  149,\n",
       "  9,\n",
       "  133,\n",
       "  4,\n",
       "  231,\n",
       "  598,\n",
       "  14,\n",
       "  4,\n",
       "  149,\n",
       "  885,\n",
       "  14,\n",
       "  60,\n",
       "  287,\n",
       "  14,\n",
       "  541,\n",
       "  393,\n",
       "  459,\n",
       "  175,\n",
       "  1,\n",
       "  131,\n",
       "  9,\n",
       "  342,\n",
       "  211,\n",
       "  886,\n",
       "  66,\n",
       "  206,\n",
       "  94,\n",
       "  363,\n",
       "  227,\n",
       "  9,\n",
       "  128,\n",
       "  548,\n",
       "  89,\n",
       "  213,\n",
       "  71,\n",
       "  235,\n",
       "  324,\n",
       "  9,\n",
       "  1,\n",
       "  431,\n",
       "  477,\n",
       "  771,\n",
       "  64,\n",
       "  780,\n",
       "  259,\n",
       "  496,\n",
       "  549,\n",
       "  9,\n",
       "  38,\n",
       "  173,\n",
       "  20,\n",
       "  248,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  12,\n",
       "  248,\n",
       "  752,\n",
       "  9,\n",
       "  8,\n",
       "  22,\n",
       "  637,\n",
       "  4,\n",
       "  24,\n",
       "  8,\n",
       "  326,\n",
       "  28,\n",
       "  637,\n",
       "  247,\n",
       "  9,\n",
       "  887,\n",
       "  181,\n",
       "  6,\n",
       "  333,\n",
       "  232,\n",
       "  188,\n",
       "  9,\n",
       "  675,\n",
       "  440,\n",
       "  57,\n",
       "  41,\n",
       "  405,\n",
       "  27,\n",
       "  347,\n",
       "  9,\n",
       "  39,\n",
       "  333,\n",
       "  39,\n",
       "  875,\n",
       "  39,\n",
       "  5,\n",
       "  9,\n",
       "  22,\n",
       "  9,\n",
       "  71,\n",
       "  5,\n",
       "  211,\n",
       "  232,\n",
       "  9,\n",
       "  238,\n",
       "  146,\n",
       "  888,\n",
       "  476,\n",
       "  550,\n",
       "  9,\n",
       "  187,\n",
       "  551,\n",
       "  875,\n",
       "  220,\n",
       "  2,\n",
       "  2,\n",
       "  547,\n",
       "  889,\n",
       "  73,\n",
       "  9,\n",
       "  188,\n",
       "  85,\n",
       "  268,\n",
       "  20,\n",
       "  248,\n",
       "  890,\n",
       "  187,\n",
       "  551,\n",
       "  891,\n",
       "  2,\n",
       "  91,\n",
       "  85,\n",
       "  428,\n",
       "  9,\n",
       "  852,\n",
       "  157,\n",
       "  460,\n",
       "  892,\n",
       "  503,\n",
       "  9,\n",
       "  40,\n",
       "  151,\n",
       "  322,\n",
       "  5,\n",
       "  14,\n",
       "  212,\n",
       "  3,\n",
       "  116,\n",
       "  287,\n",
       "  205,\n",
       "  516,\n",
       "  538,\n",
       "  14,\n",
       "  104,\n",
       "  195,\n",
       "  11,\n",
       "  9,\n",
       "  893,\n",
       "  12,\n",
       "  71,\n",
       "  4,\n",
       "  14,\n",
       "  604,\n",
       "  14,\n",
       "  2,\n",
       "  4,\n",
       "  15,\n",
       "  14,\n",
       "  1,\n",
       "  28,\n",
       "  30,\n",
       "  283,\n",
       "  14,\n",
       "  289,\n",
       "  894,\n",
       "  134,\n",
       "  63,\n",
       "  668,\n",
       "  14,\n",
       "  1,\n",
       "  14,\n",
       "  111,\n",
       "  20,\n",
       "  131,\n",
       "  88,\n",
       "  394,\n",
       "  8,\n",
       "  25,\n",
       "  14,\n",
       "  64,\n",
       "  19,\n",
       "  14,\n",
       "  15,\n",
       "  19,\n",
       "  14,\n",
       "  28,\n",
       "  895,\n",
       "  29,\n",
       "  1,\n",
       "  182,\n",
       "  434,\n",
       "  14,\n",
       "  19,\n",
       "  14,\n",
       "  631,\n",
       "  9,\n",
       "  74,\n",
       "  14,\n",
       "  65,\n",
       "  896,\n",
       "  22,\n",
       "  897,\n",
       "  13,\n",
       "  9,\n",
       "  37,\n",
       "  9,\n",
       "  8,\n",
       "  298,\n",
       "  8,\n",
       "  898,\n",
       "  298,\n",
       "  552,\n",
       "  313,\n",
       "  9,\n",
       "  49,\n",
       "  217,\n",
       "  5,\n",
       "  94,\n",
       "  331,\n",
       "  232,\n",
       "  57,\n",
       "  295,\n",
       "  57,\n",
       "  78,\n",
       "  12,\n",
       "  17,\n",
       "  227,\n",
       "  9,\n",
       "  217,\n",
       "  849,\n",
       "  4,\n",
       "  34,\n",
       "  24,\n",
       "  186,\n",
       "  9,\n",
       "  899,\n",
       "  481,\n",
       "  217,\n",
       "  5,\n",
       "  161,\n",
       "  9,\n",
       "  452,\n",
       "  339,\n",
       "  541,\n",
       "  140,\n",
       "  381,\n",
       "  41,\n",
       "  217,\n",
       "  5,\n",
       "  764,\n",
       "  781,\n",
       "  335,\n",
       "  199,\n",
       "  246,\n",
       "  302,\n",
       "  387,\n",
       "  130,\n",
       "  69,\n",
       "  9,\n",
       "  29,\n",
       "  1,\n",
       "  61,\n",
       "  33,\n",
       "  47,\n",
       "  125,\n",
       "  5,\n",
       "  376,\n",
       "  6,\n",
       "  47,\n",
       "  722,\n",
       "  65,\n",
       "  5,\n",
       "  897,\n",
       "  9,\n",
       "  45,\n",
       "  208,\n",
       "  27,\n",
       "  5,\n",
       "  4,\n",
       "  249,\n",
       "  17,\n",
       "  227,\n",
       "  9,\n",
       "  74,\n",
       "  74,\n",
       "  4,\n",
       "  897,\n",
       "  9,\n",
       "  809,\n",
       "  302,\n",
       "  5,\n",
       "  14,\n",
       "  61,\n",
       "  8,\n",
       "  81,\n",
       "  95,\n",
       "  114,\n",
       "  8,\n",
       "  2,\n",
       "  9,\n",
       "  188,\n",
       "  886,\n",
       "  9,\n",
       "  90,\n",
       "  526,\n",
       "  69,\n",
       "  766,\n",
       "  15,\n",
       "  616,\n",
       "  610,\n",
       "  41,\n",
       "  9,\n",
       "  109,\n",
       "  428,\n",
       "  90,\n",
       "  9,\n",
       "  195,\n",
       "  5,\n",
       "  2,\n",
       "  153,\n",
       "  9,\n",
       "  40,\n",
       "  4,\n",
       "  421,\n",
       "  51,\n",
       "  4,\n",
       "  297,\n",
       "  69,\n",
       "  294,\n",
       "  73,\n",
       "  95,\n",
       "  857,\n",
       "  14,\n",
       "  461,\n",
       "  900,\n",
       "  553,\n",
       "  517,\n",
       "  90,\n",
       "  678,\n",
       "  78,\n",
       "  659,\n",
       "  276,\n",
       "  30,\n",
       "  58,\n",
       "  214,\n",
       "  4,\n",
       "  656,\n",
       "  659,\n",
       "  260,\n",
       "  43],\n",
       " [27],\n",
       " [230, 6, 153, 208, 330, 136, 15, 20],\n",
       " [679, 320, 901],\n",
       " [52, 183, 16, 66],\n",
       " [161, 180],\n",
       " [27, 408, 586, 180, 600],\n",
       " [161, 236, 384],\n",
       " [232, 884, 238, 5],\n",
       " [303, 22, 7, 34, 24],\n",
       " [155, 438, 21, 535, 104, 13, 108, 120, 554, 143],\n",
       " [],\n",
       " [160, 142, 10],\n",
       " [52, 73],\n",
       " [79, 247, 680],\n",
       " [27, 7],\n",
       " [555, 282, 43, 5, 2, 17, 8],\n",
       " [902, 15, 750, 55, 1, 296, 82],\n",
       " [1, 117, 35, 446],\n",
       " [131, 360, 163, 623, 97, 163, 419, 295, 903, 204],\n",
       " [40, 224, 8, 81, 24, 25, 12],\n",
       " [46, 274, 26],\n",
       " [2, 19],\n",
       " [904, 735, 394, 48, 417, 5, 2, 41],\n",
       " [1, 198, 278],\n",
       " [16, 45, 102],\n",
       " [190],\n",
       " [6, 11, 161, 191, 384],\n",
       " [39, 127, 6, 18, 143, 195, 512],\n",
       " [454, 11, 6, 905, 339, 305],\n",
       " [28, 451, 503, 664, 815],\n",
       " [609, 304, 137, 82],\n",
       " [144, 276, 208, 30, 295, 401, 85, 129, 906, 13],\n",
       " [666, 412, 177, 29, 224, 130, 412, 224, 165, 640],\n",
       " [34, 184, 270, 242, 379, 311, 7, 556, 8, 51, 8, 34, 95, 99, 54, 681],\n",
       " [144],\n",
       " [52, 907],\n",
       " [56, 12, 4, 2, 806, 2, 55, 4, 12, 8],\n",
       " [30, 413, 436, 7, 98, 1],\n",
       " [15, 682, 11, 1],\n",
       " [908, 58, 81, 903],\n",
       " [6, 13, 174, 591, 205],\n",
       " [224],\n",
       " [557, 417, 68, 649, 26, 20, 105, 395, 35],\n",
       " [18, 490, 19],\n",
       " [97, 369, 10, 113, 11],\n",
       " [2, 76, 909, 765, 3],\n",
       " [1, 72, 29, 142],\n",
       " [96, 105, 473, 2, 134, 910, 5],\n",
       " [6, 345],\n",
       " [223, 905, 462, 683],\n",
       " [911, 3],\n",
       " [5, 86, 718, 37, 552, 357, 42, 130],\n",
       " [347, 11, 165],\n",
       " [224, 37, 239, 23, 16, 1, 45],\n",
       " [2, 170, 31, 281],\n",
       " [2, 15, 119],\n",
       " [912, 21, 15, 3, 52, 482],\n",
       " [95, 11, 29, 737],\n",
       " [192, 18],\n",
       " [21, 146, 178, 68],\n",
       " [833, 474, 4, 94, 913],\n",
       " [79, 297, 283, 53, 36],\n",
       " [914, 684, 915],\n",
       " [291, 140, 606],\n",
       " [916, 429, 6, 198],\n",
       " [558, 4, 12],\n",
       " [183],\n",
       " [12, 2, 917, 179, 12, 204],\n",
       " [19],\n",
       " [15, 45, 154, 48, 46, 183],\n",
       " [537, 269, 559, 243, 48, 12, 60, 235, 2, 152, 529, 3, 152],\n",
       " [218, 340, 770],\n",
       " [306, 67, 843, 406, 635, 155, 918, 348],\n",
       " [236, 143, 6, 50],\n",
       " [461, 177, 79, 492, 1, 329, 61, 234, 136, 209, 18, 403],\n",
       " [518, 381],\n",
       " [108, 3],\n",
       " [1, 17, 81, 299, 163],\n",
       " [39, 685, 280, 7, 2],\n",
       " [390, 15, 49],\n",
       " [194, 4, 12, 33, 300, 919, 61, 223, 134, 910, 73, 5, 86],\n",
       " [46, 823, 686, 17],\n",
       " [47, 19, 7, 337, 396],\n",
       " [10],\n",
       " [214, 165],\n",
       " [88, 200, 141, 10, 277],\n",
       " [920, 70, 76, 530],\n",
       " [50, 371, 202, 560, 261, 686, 32],\n",
       " [309, 2, 147, 279, 7, 124, 12, 425, 527, 7, 921, 68],\n",
       " [27, 922],\n",
       " [442, 363, 49, 38, 326, 12],\n",
       " [56, 3, 93, 165],\n",
       " [306, 306, 306],\n",
       " [22, 632, 34, 24, 84],\n",
       " [184, 62, 337, 638, 687, 62, 286, 923],\n",
       " [688, 72, 924, 116, 227, 629, 80, 546],\n",
       " [56, 2, 92, 307, 689],\n",
       " [58, 34, 24, 383],\n",
       " [2, 75, 260],\n",
       " [525, 828, 20, 455, 872],\n",
       " [39],\n",
       " [579, 16, 42, 200, 25],\n",
       " [501, 202, 684, 818],\n",
       " [2, 800, 3, 26],\n",
       " [181, 45, 411, 7],\n",
       " [17, 6, 7, 690, 145],\n",
       " [98, 1, 25, 23],\n",
       " [51, 245, 463, 63, 464, 640, 67],\n",
       " [220],\n",
       " [91, 365, 148, 442, 691, 7, 363, 50, 408, 39],\n",
       " [64, 19, 585, 268],\n",
       " [126, 18],\n",
       " [240, 105, 50],\n",
       " [243, 269, 191],\n",
       " [398, 55, 292, 150],\n",
       " [231, 627, 12, 199],\n",
       " [513, 5],\n",
       " [124, 20],\n",
       " [150, 619, 52, 281, 100, 665, 465, 422, 5, 25],\n",
       " [2, 5, 2, 658, 160],\n",
       " [22, 36, 24],\n",
       " [143, 925, 411],\n",
       " [926, 48],\n",
       " [489, 7, 685, 290],\n",
       " [228, 26, 53, 165, 2, 458],\n",
       " [98, 1, 77],\n",
       " [525],\n",
       " [215, 3, 26, 279, 36, 233, 215, 1],\n",
       " [307, 692, 895, 693, 108, 3, 720, 176, 477, 88, 27, 59, 693, 547, 335, 163],\n",
       " [134, 64],\n",
       " [2, 88, 762, 13, 5],\n",
       " [72, 31],\n",
       " [561, 7, 259, 253],\n",
       " [181, 45, 81, 86, 113],\n",
       " [56, 31, 458, 381, 6],\n",
       " [786, 368, 189, 689, 500, 160],\n",
       " [3, 10, 6, 388, 9],\n",
       " [15, 194],\n",
       " [69, 135, 80, 56, 401, 189, 2, 464],\n",
       " [91, 163, 9, 9, 9, 62, 132, 44, 16, 809],\n",
       " [863,\n",
       "  131,\n",
       "  261,\n",
       "  43,\n",
       "  114,\n",
       "  131,\n",
       "  261,\n",
       "  43,\n",
       "  300,\n",
       "  114,\n",
       "  131,\n",
       "  398,\n",
       "  43,\n",
       "  20,\n",
       "  410,\n",
       "  845,\n",
       "  261],\n",
       " [373, 257, 387, 333, 30, 169, 188],\n",
       " [40, 92, 796, 327],\n",
       " [7, 750, 407, 204, 7],\n",
       " [9, 12, 927, 535, 632, 864],\n",
       " [139],\n",
       " [121, 221, 32, 80, 179, 16, 11],\n",
       " [16, 45, 102, 171],\n",
       " [694],\n",
       " [240, 682, 215, 11],\n",
       " [167, 562, 264, 6, 202],\n",
       " [384, 21, 807, 11],\n",
       " [840],\n",
       " [145, 30, 308, 380, 54, 376],\n",
       " [53, 3, 925, 411, 466],\n",
       " [127, 375, 34, 24, 106],\n",
       " [93, 238, 453, 534, 769, 41, 738, 188],\n",
       " [2, 532, 314, 2, 228, 928, 540, 50, 3, 10],\n",
       " [3, 7],\n",
       " [47, 244, 80, 555, 25],\n",
       " [267],\n",
       " [219, 118, 344, 17, 169],\n",
       " [5, 549, 41],\n",
       " [132, 522, 129, 13, 678, 52, 301, 84],\n",
       " [224, 98, 1, 23],\n",
       " [6, 87, 929, 46, 17, 3, 82, 60, 326, 13, 520],\n",
       " [8, 38, 558, 273, 514, 176],\n",
       " [20, 651, 46, 362],\n",
       " [258, 3, 47, 256, 456],\n",
       " [96, 3],\n",
       " [2, 604],\n",
       " [1, 316, 245],\n",
       " [393, 515, 490],\n",
       " [293, 79, 132],\n",
       " [68, 1, 99],\n",
       " [96, 11, 106, 23, 57],\n",
       " [605, 111, 930, 78],\n",
       " [56, 1, 31, 507, 382, 1, 733, 55, 274, 357],\n",
       " [229],\n",
       " [4, 31, 668, 302, 31, 741, 266, 427, 647, 67],\n",
       " [71, 64, 342, 496],\n",
       " [429, 3, 50],\n",
       " [64, 192, 90, 335, 559, 290, 563, 59],\n",
       " [518, 75, 313],\n",
       " [434, 76, 695, 678, 196],\n",
       " [56, 348, 40, 151, 102, 16, 17, 20, 24],\n",
       " [73, 83, 147, 36, 42, 203, 107, 556, 696],\n",
       " [27, 257, 71, 143, 105],\n",
       " [185, 279, 691, 408, 70, 20, 294, 35],\n",
       " [931, 437, 204, 220, 73],\n",
       " [21, 7, 1, 564, 249, 932, 565],\n",
       " [58, 73, 24],\n",
       " [176, 933, 201, 933, 262, 719],\n",
       " [203],\n",
       " [341, 3, 55, 16],\n",
       " [663, 258],\n",
       " [18, 39, 50, 52, 371, 885, 123, 392],\n",
       " [10, 60, 345],\n",
       " [2, 167, 11, 190, 222, 462, 123],\n",
       " [168],\n",
       " [2, 256, 447, 934, 5, 729, 136],\n",
       " [18, 616, 104],\n",
       " [21, 87, 82],\n",
       " [751, 36, 126],\n",
       " [175, 1, 28, 148, 132, 891],\n",
       " [27, 505, 785, 845, 219, 935, 113],\n",
       " [20, 32, 119, 7, 848, 728],\n",
       " [20, 32, 99, 264],\n",
       " [16],\n",
       " [936, 125, 928, 296, 773, 451],\n",
       " [238, 238, 19, 5],\n",
       " [27, 48, 179, 756],\n",
       " [11, 501, 334],\n",
       " [16, 181, 45, 35],\n",
       " [137, 920],\n",
       " [206, 61, 551, 74, 67],\n",
       " [78, 219, 937, 43, 435],\n",
       " [1, 72, 214, 22, 911],\n",
       " [58, 938, 24, 91, 29, 86, 617, 103, 16],\n",
       " [11, 26, 305, 26, 127],\n",
       " [642, 120, 3, 173],\n",
       " [260],\n",
       " [5, 390],\n",
       " [218, 340, 159],\n",
       " [58, 209, 18, 24],\n",
       " [144],\n",
       " [576, 32, 314],\n",
       " [8, 1, 17, 259],\n",
       " [3, 745],\n",
       " [260, 53, 26, 83],\n",
       " [333, 2, 612, 2],\n",
       " [300, 499, 87, 44, 79, 204, 2, 217, 116, 315],\n",
       " [223, 237, 786, 4, 342, 64, 566, 536, 5, 445],\n",
       " [209, 18, 83],\n",
       " [171, 299, 136],\n",
       " [133, 1, 139],\n",
       " [4, 774, 103, 153, 140, 476, 59, 93, 1, 186],\n",
       " [607, 25],\n",
       " [134, 518, 154, 534, 93],\n",
       " [21, 584, 237, 288, 88, 45, 35],\n",
       " [99, 681, 60, 217, 487, 939, 636],\n",
       " [15, 144],\n",
       " [],\n",
       " [382, 72, 282],\n",
       " [690, 70],\n",
       " [9, 62, 43, 110, 136, 7, 925],\n",
       " [297, 103, 576],\n",
       " [110, 15, 12, 4],\n",
       " [147, 36],\n",
       " [1, 31, 567],\n",
       " [41, 212],\n",
       " [5, 20, 32, 682, 110, 17, 496, 64, 229, 3, 940, 53, 12, 2, 239, 941],\n",
       " [382, 83, 209, 18, 30, 539],\n",
       " [75, 317, 346, 7, 62, 116],\n",
       " [18, 96, 45],\n",
       " [389, 5, 313, 552],\n",
       " [150, 4],\n",
       " [239, 23, 222, 13],\n",
       " [22],\n",
       " [19, 99, 47, 166],\n",
       " [50, 3, 365, 3, 327],\n",
       " [2, 214, 590, 49, 48, 373, 2, 590, 550, 12, 416],\n",
       " [533, 275],\n",
       " [942, 531],\n",
       " [16, 86, 503, 74, 498, 29],\n",
       " [187, 611, 666],\n",
       " [177, 415, 8, 942],\n",
       " [6, 379],\n",
       " [943, 106, 521, 205, 944, 205, 181, 45, 11, 171, 255],\n",
       " [61, 127, 322, 170, 55],\n",
       " [265, 3, 545, 269, 30, 895, 693, 800, 183, 749, 31, 4, 3, 64, 281, 523],\n",
       " [643, 3, 167],\n",
       " [17, 62, 284, 424],\n",
       " [10, 60, 3],\n",
       " [44, 317],\n",
       " [250, 3],\n",
       " [39],\n",
       " [135, 69, 283, 30, 145, 207, 187, 29, 1, 11, 115],\n",
       " [917, 55, 273],\n",
       " [133, 6, 73],\n",
       " [240, 1, 28, 254, 91],\n",
       " [172, 292, 243, 438, 901, 172, 392],\n",
       " [82, 945, 413],\n",
       " [193, 593, 177, 935],\n",
       " [669, 946, 390, 15, 354],\n",
       " [597, 85, 947, 5, 56, 887, 2, 22, 5, 28, 109, 69],\n",
       " [931, 60, 51, 13, 697, 462, 123, 29, 688, 26, 10, 18],\n",
       " [121, 275, 484, 121, 226],\n",
       " [416, 245, 56, 440, 23],\n",
       " [698, 501, 511],\n",
       " [190, 395],\n",
       " [15, 45, 11, 25, 323, 11],\n",
       " [543, 43, 21],\n",
       " [394, 163, 473, 19, 529, 696],\n",
       " [140, 120, 121, 6, 10, 109, 948, 143],\n",
       " [133, 3, 7, 117],\n",
       " [291, 12],\n",
       " [153, 3],\n",
       " [6, 7],\n",
       " [11, 664, 467, 10, 211, 1, 105],\n",
       " [10, 18, 355],\n",
       " [7, 315, 699],\n",
       " [88, 520, 33, 73, 279],\n",
       " [556, 54, 43, 22],\n",
       " [1, 109, 331, 15, 107, 79, 78],\n",
       " [284],\n",
       " [12, 865, 223, 86, 700, 700, 2, 504, 364, 150, 52, 183],\n",
       " [447],\n",
       " [949, 263, 174],\n",
       " [687, 62, 116, 544, 294],\n",
       " [369, 855, 46, 949, 288, 45, 68],\n",
       " [132, 277],\n",
       " [460, 132, 30, 10, 443, 155, 127, 10, 701, 486, 165, 12, 168],\n",
       " [3, 128, 756],\n",
       " [15, 97, 31, 73, 3, 8],\n",
       " [42, 88, 12, 25, 23, 175, 1, 30, 813, 18, 37, 336],\n",
       " [30, 161, 548],\n",
       " [6],\n",
       " [17, 20],\n",
       " [79, 69, 267, 558, 7],\n",
       " [504, 57, 115, 893, 905, 225, 36],\n",
       " [235, 156, 108, 945, 104, 6, 176, 159, 592],\n",
       " [18, 268, 210],\n",
       " [297, 69, 199, 407, 316, 245, 104, 33],\n",
       " [483, 906, 203],\n",
       " [1, 129, 112],\n",
       " [99, 861, 346, 51, 13, 184, 244],\n",
       " [185, 60],\n",
       " [39, 87, 127],\n",
       " [31, 172, 33, 8],\n",
       " [950, 2, 19],\n",
       " [162, 102],\n",
       " [468, 935, 622, 591, 799, 469, 462, 80],\n",
       " [133, 16, 45, 7, 87],\n",
       " [17, 6],\n",
       " [2, 59, 3, 93, 12, 31, 421, 397, 12],\n",
       " [39, 303, 365, 685],\n",
       " [17, 13, 407],\n",
       " [119, 27, 28, 119],\n",
       " [20, 929, 415, 13, 17],\n",
       " [385],\n",
       " [133, 12, 11, 104],\n",
       " [196, 866, 209, 163, 8, 209, 1, 312, 10],\n",
       " [31, 567],\n",
       " [951],\n",
       " [11, 141, 16, 24, 336, 401, 665],\n",
       " [241, 21, 120],\n",
       " [181],\n",
       " [324, 4, 226, 15, 19],\n",
       " [83, 18],\n",
       " [108, 109, 10, 142],\n",
       " [500, 34, 184, 100, 282, 3],\n",
       " [151, 702, 4, 16, 296, 89, 213, 239, 127],\n",
       " [243, 6],\n",
       " [133, 5, 307, 134, 910],\n",
       " [150, 78, 41],\n",
       " [69, 44, 207, 220, 464, 36],\n",
       " [506, 11, 594],\n",
       " [531, 18, 19],\n",
       " [25, 495, 9, 103, 631, 952, 72, 860, 13, 372, 191, 356, 252],\n",
       " [621],\n",
       " [567],\n",
       " [238, 3, 310, 207, 23],\n",
       " [257, 40, 63, 443, 103, 161],\n",
       " [277, 454, 375, 130, 486, 165, 12, 172, 568, 488],\n",
       " [34, 815, 442, 922],\n",
       " [129, 112, 13],\n",
       " [498, 4, 2, 200, 523, 338, 486, 13, 65, 173],\n",
       " [196],\n",
       " [10, 65],\n",
       " [648, 76, 803, 29, 703, 704, 953, 360, 59, 704, 17, 1, 564],\n",
       " [877, 35],\n",
       " [22, 34, 95, 100, 34, 184, 62, 8, 22, 26, 20, 225],\n",
       " [631, 14, 74, 477, 128, 19, 28, 954, 153, 569, 782, 128],\n",
       " [306, 62, 132, 37, 70, 259, 156, 130, 165, 80, 60, 509],\n",
       " [262, 755],\n",
       " [432, 7, 81, 299, 49],\n",
       " [463, 408, 955, 569, 7, 212],\n",
       " [15, 94, 347, 73, 33],\n",
       " [76, 68, 43, 4, 900, 71, 197, 76, 376],\n",
       " [3],\n",
       " [31, 831, 956, 125, 115],\n",
       " [16, 545, 182],\n",
       " [3],\n",
       " [94, 193],\n",
       " [1, 148, 19, 337, 106, 8, 288, 16, 45, 171],\n",
       " [12, 656, 131, 29, 1, 539, 141, 11, 43],\n",
       " [470, 1, 554, 120, 669, 80],\n",
       " [29, 1],\n",
       " [183, 7],\n",
       " [138, 488, 570, 71, 323],\n",
       " [62, 574, 727],\n",
       " [109, 160, 347, 30, 752, 878],\n",
       " [954, 289, 705, 246, 3, 705, 139],\n",
       " [460, 8, 510, 288, 139],\n",
       " [55, 171, 72, 472, 394, 72, 290],\n",
       " [6, 36, 139],\n",
       " [201, 352, 71, 34, 184, 30],\n",
       " [21, 198, 479, 498],\n",
       " [661, 375],\n",
       " [7, 176],\n",
       " [60, 201],\n",
       " [538, 194, 957],\n",
       " [43, 61, 22, 93, 450, 128, 41, 85],\n",
       " [1],\n",
       " [237, 12, 210, 57],\n",
       " [37, 483, 11],\n",
       " [25, 59],\n",
       " [40, 15, 151, 2, 22, 269, 559, 683],\n",
       " [27, 6],\n",
       " [933, 958],\n",
       " [159, 92],\n",
       " [959, 944, 13, 51],\n",
       " [35, 6, 31, 294, 104, 583, 25, 348, 316, 396],\n",
       " [960, 5, 109, 571],\n",
       " [196, 7],\n",
       " [175, 1, 454, 2, 28, 919],\n",
       " [561, 5, 1, 48, 76],\n",
       " [30, 479, 67, 703, 115, 30, 488, 43],\n",
       " [283, 252, 79, 103, 40, 566, 86, 8],\n",
       " [414, 86, 617, 103, 88],\n",
       " [701, 287, 18, 247, 12, 867, 193, 961],\n",
       " [82, 54, 32, 645, 873, 424, 308],\n",
       " [27, 35],\n",
       " [217, 242, 706, 20, 248, 20, 217, 13, 70, 75, 456],\n",
       " [286, 2, 124, 100],\n",
       " [53, 26, 180, 555, 15, 255, 197, 299, 94],\n",
       " [918, 108, 31, 80, 179, 193],\n",
       " [41, 8, 28, 3, 419, 280, 19, 419],\n",
       " [158, 65],\n",
       " [30, 59, 499, 165, 265, 189],\n",
       " [6, 10],\n",
       " [461],\n",
       " [937,\n",
       "  899,\n",
       "  182,\n",
       "  962,\n",
       "  821,\n",
       "  20,\n",
       "  847,\n",
       "  292,\n",
       "  188,\n",
       "  963,\n",
       "  164,\n",
       "  432,\n",
       "  641,\n",
       "  13,\n",
       "  41,\n",
       "  553,\n",
       "  452],\n",
       " [279, 457, 70, 304, 26, 147, 36, 76],\n",
       " [55, 253],\n",
       " [27, 38],\n",
       " [18, 964, 120],\n",
       " [],\n",
       " [416, 444],\n",
       " [15, 347, 903, 4, 31, 4, 943, 661, 334],\n",
       " [211, 741, 396, 248],\n",
       " [414, 47, 4, 29, 16],\n",
       " [355, 232],\n",
       " [126, 18, 470, 32, 179, 12, 266, 57, 13, 60, 155],\n",
       " [744, 131, 672, 28, 19, 10, 249],\n",
       " [4, 356, 378, 422],\n",
       " [807, 6, 26],\n",
       " [744, 318, 77, 10, 18],\n",
       " [22, 18, 10, 24, 121, 3, 120, 32, 116],\n",
       " [40, 162, 327, 3, 26, 228, 50],\n",
       " [100, 22, 24],\n",
       " [464, 323, 305, 204, 26, 6, 18, 338, 10],\n",
       " [442, 95, 8, 22, 350],\n",
       " [20, 872, 248, 387, 4],\n",
       " [162],\n",
       " [133, 77, 26, 10],\n",
       " [734, 289, 5, 6, 38, 106, 93],\n",
       " [193, 226],\n",
       " [223, 23],\n",
       " [707, 340, 162, 51, 123, 325, 73],\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "54 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=mse but model compiled with binary_crossentropy. Data may not match loss function!\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.76766091 0.76713762        nan        nan 0.76452119 0.76923077\n",
      "        nan        nan 0.75771847 0.7566719         nan        nan\n",
      " 0.77341706 0.77394035        nan        nan 0.77237049 0.76766091\n",
      "        nan        nan 0.76347462 0.76975406        nan        nan\n",
      " 0.73678702 0.7414966         nan        nan 0.76295133 0.7566719\n",
      "        nan        nan 0.77969649 0.78074307        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.780743 using {'batch_size': 128, 'epochs': 20, 'loss': 'binary_crossentropy', 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "# find best hyperparameters using grid search\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(optimizer='rmsprop', loss='binary_crossentropy'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 32, input_length=max_len))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [32, 64, 128],\n",
    "                'epochs': [10, 15, 20],\n",
    "                'optimizer': ['adam', 'rmsprop'],\n",
    "                'loss': ['binary_crossentropy', 'mse']}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(sequences_matrix_train, y_train)\n",
    "\n",
    "# print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 32)           32000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56897 (222.25 KB)\n",
      "Trainable params: 56897 (222.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "15/15 [==============================] - 6s 196ms/step - loss: 0.6935 - acc: 0.4882 - precision: 0.4901 - recall: 0.4656 - true_positives: 447.0000 - true_negatives: 486.0000 - false_positives: 465.0000 - false_negatives: 513.0000\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 3s 186ms/step - loss: 0.6912 - acc: 0.5819 - precision: 0.5756 - recall: 0.6385 - true_positives: 613.0000 - true_negatives: 499.0000 - false_positives: 452.0000 - false_negatives: 347.0000\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 0.6873 - acc: 0.6102 - precision: 0.6965 - recall: 0.3969 - true_positives: 381.0000 - true_negatives: 785.0000 - false_positives: 166.0000 - false_negatives: 579.0000\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.6784 - acc: 0.6792 - precision: 0.6689 - recall: 0.7156 - true_positives: 687.0000 - true_negatives: 611.0000 - false_positives: 340.0000 - false_negatives: 273.0000\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 3s 189ms/step - loss: 0.6568 - acc: 0.7242 - precision: 0.7515 - recall: 0.6740 - true_positives: 647.0000 - true_negatives: 737.0000 - false_positives: 214.0000 - false_negatives: 313.0000\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.6176 - acc: 0.7122 - precision: 0.6934 - recall: 0.7656 - true_positives: 735.0000 - true_negatives: 626.0000 - false_positives: 325.0000 - false_negatives: 225.0000\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.5558 - acc: 0.7975 - precision: 0.7975 - recall: 0.8000 - true_positives: 768.0000 - true_negatives: 756.0000 - false_positives: 195.0000 - false_negatives: 192.0000\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 3s 182ms/step - loss: 0.5116 - acc: 0.8022 - precision: 0.7798 - recall: 0.8448 - true_positives: 811.0000 - true_negatives: 722.0000 - false_positives: 229.0000 - false_negatives: 149.0000\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 3s 189ms/step - loss: 0.4564 - acc: 0.8441 - precision: 0.8653 - recall: 0.8167 - true_positives: 784.0000 - true_negatives: 829.0000 - false_positives: 122.0000 - false_negatives: 176.0000\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 0.4102 - acc: 0.8514 - precision: 0.8603 - recall: 0.8406 - true_positives: 807.0000 - true_negatives: 820.0000 - false_positives: 131.0000 - false_negatives: 153.0000\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 0.3736 - acc: 0.8603 - precision: 0.8682 - recall: 0.8510 - true_positives: 817.0000 - true_negatives: 827.0000 - false_positives: 124.0000 - false_negatives: 143.0000\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 3s 182ms/step - loss: 0.4826 - acc: 0.8409 - precision: 0.8417 - recall: 0.8417 - true_positives: 808.0000 - true_negatives: 799.0000 - false_positives: 152.0000 - false_negatives: 152.0000\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 3s 184ms/step - loss: 0.3247 - acc: 0.8802 - precision: 0.8977 - recall: 0.8594 - true_positives: 825.0000 - true_negatives: 857.0000 - false_positives: 94.0000 - false_negatives: 135.0000\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 3s 189ms/step - loss: 0.3001 - acc: 0.8844 - precision: 0.8910 - recall: 0.8771 - true_positives: 842.0000 - true_negatives: 848.0000 - false_positives: 103.0000 - false_negatives: 118.0000\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 0.2854 - acc: 0.8891 - precision: 0.8953 - recall: 0.8823 - true_positives: 847.0000 - true_negatives: 852.0000 - false_positives: 99.0000 - false_negatives: 113.0000\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 0.2656 - acc: 0.8990 - precision: 0.8999 - recall: 0.8990 - true_positives: 863.0000 - true_negatives: 855.0000 - false_positives: 96.0000 - false_negatives: 97.0000\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 0.2491 - acc: 0.9016 - precision: 0.8996 - recall: 0.9052 - true_positives: 869.0000 - true_negatives: 854.0000 - false_positives: 97.0000 - false_negatives: 91.0000\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 0.2350 - acc: 0.9058 - precision: 0.9176 - recall: 0.8927 - true_positives: 857.0000 - true_negatives: 874.0000 - false_positives: 77.0000 - false_negatives: 103.0000\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 0.2285 - acc: 0.9100 - precision: 0.9079 - recall: 0.9135 - true_positives: 877.0000 - true_negatives: 862.0000 - false_positives: 89.0000 - false_negatives: 83.0000\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 3s 182ms/step - loss: 0.2133 - acc: 0.9168 - precision: 0.9176 - recall: 0.9167 - true_positives: 880.0000 - true_negatives: 872.0000 - false_positives: 79.0000 - false_negatives: 80.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2400cb63b10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print metrics using best hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32, input_length=max_len))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', 'Precision', 'Recall', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(sequences_matrix_train, y_train, batch_size=128, epochs=20) #, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa(score):\n",
    "    tp = score[4]\n",
    "    tn = score[5]\n",
    "    fp = score[6]\n",
    "    fn = score[7]\n",
    "    k = (2*(tp*tn-fn*fp)) / ( (tp+fp) * (fp+tn) + (tp+fn) * (fn+tn) )\n",
    "    return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1953485608100891\n",
      "Train accuracy: 0.9277864694595337\n",
      "Train precision: 0.9363057613372803\n",
      "Train recall: 0.918749988079071\n",
      "Train f1-score: 0.9274448030337016\n",
      "Train kappa: 0.855582608009936\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(sequences_matrix_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "print('Train precision:', score[2])\n",
    "print('Train recall:', score[3])\n",
    "f1 = 2 * (score[2] * score[3]) / (score[2] + score[3])\n",
    "print('Train f1-score:', f1)\n",
    "print('Train kappa:', kappa(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.47540444135665894\n",
      "Test accuracy: 0.79756098985672\n",
      "Test precision: 0.8004807829856873\n",
      "Test recall: 0.8004807829856873\n",
      "Test f1-score: 0.8004807829856873\n",
      "Test kappa: 0.5950352246763138\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(sequences_matrix_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "f1 = 2 * (score[2] * score[3]) / (score[2] + score[3])\n",
    "print('Test f1-score:', f1)\n",
    "print('Test kappa:', kappa(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "54 fits failed out of a total of 108.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 1491, in fit\n",
      "    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 760, in fit\n",
      "    self._fit(\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 926, in _fit\n",
      "    self._check_model_compatibility(y)\n",
      "  File \"c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py\", line 569, in _check_model_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: loss=mse but model compiled with binary_crossentropy. Data may not match loss function!\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.70591313 0.7299843         nan        nan 0.69492412 0.72213501\n",
      "        nan        nan 0.69283098 0.66562009        nan        nan\n",
      " 0.62009419 0.73312402        nan        nan 0.69387755 0.72108844\n",
      "        nan        nan 0.71219257 0.72161172        nan        nan\n",
      " 0.72213501 0.69335426        nan        nan 0.67346939 0.71271586\n",
      "        nan        nan 0.72841444 0.73835688        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    }
   ],
   "source": [
    "#use grid search to find best hyperparameters for the RNN model\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(optimizer='rmsprop', loss='binary_crossentropy'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 32, input_length=max_len))\n",
    "    model.add(SimpleRNN(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {'batch_size': [32, 64, 128],\n",
    "                'epochs': [10, 15, 20],\n",
    "                'optimizer': ['adam', 'rmsprop'],\n",
    "                'loss': ['binary_crossentropy', 'mse']}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(sequences_matrix_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.738357 using {'batch_size': 128, 'epochs': 20, 'loss': 'binary_crossentropy', 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 150, 32)           32000     \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38273 (149.50 KB)\n",
      "Trainable params: 38273 (149.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "15/15 [==============================] - 3s 63ms/step - loss: 0.6931 - acc: 0.5264 - precision: 0.5279 - recall: 0.5427 - true_positives: 521.0000 - true_negatives: 485.0000 - false_positives: 466.0000 - false_negatives: 439.0000\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.6776 - acc: 0.6295 - precision: 0.6165 - recall: 0.6948 - true_positives: 667.0000 - true_negatives: 536.0000 - false_positives: 415.0000 - false_negatives: 293.0000\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 1s 64ms/step - loss: 0.6495 - acc: 0.7661 - precision: 0.8163 - recall: 0.6896 - true_positives: 662.0000 - true_negatives: 802.0000 - false_positives: 149.0000 - false_negatives: 298.0000\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.5980 - acc: 0.8158 - precision: 0.8108 - recall: 0.8260 - true_positives: 793.0000 - true_negatives: 766.0000 - false_positives: 185.0000 - false_negatives: 167.0000\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 0.5337 - acc: 0.8069 - precision: 0.8539 - recall: 0.7427 - true_positives: 713.0000 - true_negatives: 829.0000 - false_positives: 122.0000 - false_negatives: 247.0000\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.4834 - acc: 0.8095 - precision: 0.8163 - recall: 0.8010 - true_positives: 769.0000 - true_negatives: 778.0000 - false_positives: 173.0000 - false_negatives: 191.0000\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.3941 - acc: 0.8932 - precision: 0.9276 - recall: 0.8542 - true_positives: 820.0000 - true_negatives: 887.0000 - false_positives: 64.0000 - false_negatives: 140.0000\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 0.3354 - acc: 0.9021 - precision: 0.9187 - recall: 0.8833 - true_positives: 848.0000 - true_negatives: 876.0000 - false_positives: 75.0000 - false_negatives: 112.0000\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.2835 - acc: 0.9205 - precision: 0.9372 - recall: 0.9021 - true_positives: 866.0000 - true_negatives: 893.0000 - false_positives: 58.0000 - false_negatives: 94.0000\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.3541 - acc: 0.8378 - precision: 0.8457 - recall: 0.8281 - true_positives: 795.0000 - true_negatives: 806.0000 - false_positives: 145.0000 - false_negatives: 165.0000\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 0.2452 - acc: 0.9152 - precision: 0.9503 - recall: 0.8771 - true_positives: 842.0000 - true_negatives: 907.0000 - false_positives: 44.0000 - false_negatives: 118.0000\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1988 - acc: 0.9398 - precision: 0.9480 - recall: 0.9312 - true_positives: 894.0000 - true_negatives: 902.0000 - false_positives: 49.0000 - false_negatives: 66.0000\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.1866 - acc: 0.9414 - precision: 0.9398 - recall: 0.9438 - true_positives: 906.0000 - true_negatives: 893.0000 - false_positives: 58.0000 - false_negatives: 54.0000\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.6352 - acc: 0.7331 - precision: 0.7855 - recall: 0.6448 - true_positives: 619.0000 - true_negatives: 782.0000 - false_positives: 169.0000 - false_negatives: 341.0000\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.7781 - acc: 0.6625 - precision: 0.6677 - recall: 0.6531 - true_positives: 627.0000 - true_negatives: 639.0000 - false_positives: 312.0000 - false_negatives: 333.0000\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 0.2596 - acc: 0.8990 - precision: 0.9050 - recall: 0.8927 - true_positives: 857.0000 - true_negatives: 861.0000 - false_positives: 90.0000 - false_negatives: 103.0000\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 1s 63ms/step - loss: 0.2656 - acc: 0.8885 - precision: 0.8879 - recall: 0.8906 - true_positives: 855.0000 - true_negatives: 843.0000 - false_positives: 108.0000 - false_negatives: 105.0000\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.3380 - acc: 0.8430 - precision: 0.8784 - recall: 0.7979 - true_positives: 766.0000 - true_negatives: 845.0000 - false_positives: 106.0000 - false_negatives: 194.0000\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 0.2914 - acc: 0.8713 - precision: 0.8847 - recall: 0.8552 - true_positives: 821.0000 - true_negatives: 844.0000 - false_positives: 107.0000 - false_negatives: 139.0000\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 0.1683 - acc: 0.9335 - precision: 0.9532 - recall: 0.9125 - true_positives: 876.0000 - true_negatives: 908.0000 - false_positives: 43.0000 - false_negatives: 84.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x240084d4310>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print metrics using best hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32, input_length=max_len))\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc', 'Precision', 'Recall', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(sequences_matrix_train, y_train, batch_size=128, epochs=20) #, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1475353091955185\n",
      "Train accuracy: 0.9492412209510803\n",
      "Train precision: 0.9371833801269531\n",
      "Train recall: 0.9635416865348816\n",
      "Train f1-score: 0.9501797714131418\n",
      "Train kappa: 0.8984667057754466\n"
     ]
    }
   ],
   "source": [
    "#train metrics\n",
    "score = model.evaluate(sequences_matrix_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "print('Train precision:', score[2])\n",
    "print('Train recall:', score[3])\n",
    "f1 = 2 * (score[2] * score[3]) / (score[2] + score[3])\n",
    "print('Train f1-score:', f1)\n",
    "print('Train kappa:', kappa(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.49951648712158203\n",
      "Test accuracy: 0.7865853905677795\n",
      "Test precision: 0.7580299973487854\n",
      "Test recall: 0.8509615659713745\n",
      "Test f1-score: 0.8018120272378896\n",
      "Test kappa: 0.5723005758294687\n"
     ]
    }
   ],
   "source": [
    "#test metrics\n",
    "score = model.evaluate(sequences_matrix_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "f1 = 2 * (score[2] * score[3]) / (score[2] + score[3])\n",
    "print('Test f1-score:', f1)\n",
    "print('Test kappa:', kappa(score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
